#ifndef APY_H
#define APY_H

static const struct {
    int 	 size;
    const char	 file_data[32604 + 1];
} AssembleSound = {
    32604 + 1,
    "#!/usr/bin/env python3\n"
    "from collections import namedtuple, OrderedDict\n"
    "from json import JSONDecoder\n"
    "import os\n"
    "import re\n"
    "import struct\n"
    "import subprocess\n"
    "import sys\n"
    "\n"
    "TYPE_CTL = 1\n"
    "TYPE_TBL = 2\n"
    "\n"
    "STACK_TRACES = False\n"
    "DUMP_INDIVIDUAL_BINS = False\n"
    "ENDIAN_MARKER = \">\"\n"
    "WORD_BYTES = 4\n"
    "\n"
    "orderedJsonDecoder = JSONDecoder(object_pairs_hook=OrderedDict)\n"
    "\n"
    "\n"
    "class Aifc:\n"
    "    def __init__(self, name, fname, data, sample_rate, book, loop):\n"
    "        self.name = name\n"
    "        self.fname = fname\n"
    "        self.data = data\n"
    "        self.sample_rate = sample_rate\n"
    "        self.book = book\n"
    "        self.loop = loop\n"
    "        self.used = False\n"
    "        self.offset = None\n"
    "\n"
    "\n"
    "class SampleBank:\n"
    "    def __init__(self, name, entries):\n"
    "        self.name = name\n"
    "        self.uses = []\n"
    "        self.entries = entries\n"
    "        self.name_to_entry = {}\n"
    "        for e in entries:\n"
    "            self.name_to_entry[e.name] = e\n"
    "\n"
    "\n"
    "Book = namedtuple(\"Book\", [\"order\", \"npredictors\", \"table\"])\n"
    "Loop = namedtuple(\"Loop\", [\"start\", \"end\", \"count\", \"state\"])\n"
    "Bank = namedtuple(\"Bank\", [\"name\", \"sample_bank\", \"json\"])\n"
    "\n"
    "\n"
    "def align(val, al):\n"
    "    return (val + (al - 1)) & -al\n"
    "\n"
    "\n"
    "def fail(msg):\n"
    "    print(msg, file=sys.stderr)\n"
    "    if STACK_TRACES:\n"
    "        raise Exception(\"re-raising exception\")\n"
    "    # sys.exit(1)\n"
    "\n"
    "\n"
    "def validate(cond, msg, forstr=\"\"):\n"
    "    if not cond:\n"
    "        if forstr:\n"
    "            msg += \" for \" + forstr\n"
    "        raise Exception(msg)\n"
    "\n"
    "\n"
    "def strip_comments(string):\n"
    "    string = re.sub(re.compile(\"/\\*.*?\\*/\", re.DOTALL), \"\", string)\n"
    "    return re.sub(re.compile(\"//.*?\\n\"), \"\", string)\n"
    "\n"
    "\n"
    "def pack(fmt, *args):\n"
    "    if WORD_BYTES == 4:\n"
    "        fmt = fmt.replace('P', 'I').replace('X', '')\n"
    "    else:\n"
    "        fmt = fmt.replace('P', 'Q').replace('X', 'xxxx')\n"
    "    return struct.pack(ENDIAN_MARKER + fmt, *args)\n"
    "\n"
    "\n"
    "def to_bcd(num):\n"
    "    assert num >= 0\n"
    "    shift = 0\n"
    "    ret = 0\n"
    "    while num:\n"
    "        ret |= (num % 10) << shift\n"
    "        shift += 4\n"
    "        num //= 10\n"
    "    return ret\n"
    "\n"
    "\n"
    "def parse_f80(data):\n"
    "    exp_bits, mantissa_bits = struct.unpack(\">HQ\", data)\n"
    "    sign_bit = exp_bits & 2 ** 15\n"
    "    exp_bits ^= sign_bit\n"
    "    sign = -1 if sign_bit else 1\n"
    "    if exp_bits == mantissa_bits == 0:\n"
    "        return sign * 0.0\n"
    "    validate(exp_bits != 0, \"sample rate is a denormal\")\n"
    "    validate(exp_bits != 0x7FFF, \"sample rate is infinity/nan\")\n"
    "    mant = float(mantissa_bits) / 2 ** 63\n"
    "    return sign * mant * pow(2, exp_bits - 0x3FFF)\n"
    "\n"
    "\n"
    "def parse_aifc_loop(data):\n"
    "    validate(len(data) == 48, \"loop chunk size should be 48\")\n"
    "    version, nloops, start, end, count = struct.unpack(\">HHIIi\", data[:16])\n"
    "    validate(version == 1, \"loop version doesn't match\")\n"
    "    validate(nloops == 1, \"only one loop is supported\")\n"
    "    state = []\n"
    "    for i in range(16, len(data), 2):\n"
    "        state.append(struct.unpack(\">h\", data[i : i + 2])[0])\n"
    "    return Loop(start, end, count, state)\n"
    "\n"
    "\n"
    "def parse_aifc_book(data):\n"
    "    version, order, npredictors = struct.unpack(\">hhh\", data[:6])\n"
    "    validate(version == 1, \"codebook version doesn't match\")\n"
    "    validate(\n"
    "        len(data) == 6 + 16 * order * npredictors,\n"
    "        \"predictor book chunk size doesn't match\",\n"
    "    )\n"
    "    table = []\n"
    "    for i in range(6, len(data), 2):\n"
    "        table.append(struct.unpack(\">h\", data[i : i + 2])[0])\n"
    "    return Book(order, npredictors, table)\n"
    "\n"
    "\n"
    "def parse_aifc(data, name, fname):\n"
    "    validate(data[:4] == b\"FORM\", \"must start with FORM\")\n"
    "    validate(data[8:12] == b\"AIFC\", \"format must be AIFC\")\n"
    "    i = 12\n"
    "    sections = []\n"
    "    while i < len(data):\n"
    "        tp = data[i : i + 4]\n"
    "        le, = struct.unpack(\">I\", data[i + 4 : i + 8])\n"
    "        i += 8\n"
    "        sections.append((tp, data[i : i + le]))\n"
    "        i = align(i + le, 2)\n"
    "\n"
    "    audio_data = None\n"
    "    vadpcm_codes = None\n"
    "    vadpcm_loops = None\n"
    "    sample_rate = None\n"
    "\n"
    "    for (tp, data) in sections:\n"
    "        if tp == b\"APPL\" and data[:4] == b\"stoc\":\n"
    "            plen = data[4]\n"
    "            tp = data[5 : 5 + plen]\n"
    "            data = data[align(5 + plen, 2) :]\n"
    "            if tp == b\"VADPCMCODES\":\n"
    "                vadpcm_codes = data\n"
    "            elif tp == b\"VADPCMLOOPS\":\n"
    "                vadpcm_loops = data\n"
    "        elif tp == b\"SSND\":\n"
    "            audio_data = data[8:]\n"
    "        elif tp == b\"COMM\":\n"
    "            sample_rate = parse_f80(data[8:18])\n"
    "\n"
    "    validate(sample_rate is not None, \"no COMM section\")\n"
    "    validate(audio_data is not None, \"no SSND section\")\n"
    "    validate(vadpcm_codes is not None, \"no VADPCM table\")\n"
    "\n"
    "    book = parse_aifc_book(vadpcm_codes)\n"
    "    loop = parse_aifc_loop(vadpcm_loops) if vadpcm_loops is not None else None\n"
    "    return Aifc(name, fname, audio_data, sample_rate, book, loop)\n"
    "\n"
    "\n"
    "class ReserveSerializer:\n"
    "    def __init__(self):\n"
    "        self.parts = []\n"
    "        self.sizes = []\n"
    "        self.size = 0\n"
    "\n"
    "    def add(self, part):\n"
    "        assert isinstance(part, (bytes, list))\n"
    "        self.parts.append(part)\n"
    "        self.sizes.append(len(part))\n"
    "        self.size += len(part)\n"
    "\n"
    "    def reserve(self, space):\n"
    "        li = []\n"
    "        self.parts.append(li)\n"
    "        self.sizes.append(space)\n"
    "        self.size += space\n"
    "        return li\n"
    "\n"
    "    def align(self, alignment):\n"
    "        new_size = (self.size + alignment - 1) & -alignment\n"
    "        self.add((new_size - self.size) * b\"\\0\")\n"
    "\n"
    "    def finish(self):\n"
    "        flat_parts = []\n"
    "        for (li, si) in zip(self.parts, self.sizes):\n"
    "            if isinstance(li, list):\n"
    "                li = b\"\".join(li)\n"
    "            assert (\n"
    "                len(li) == si\n"
    "            ), \"unfulfilled reservation of size {}, only got {}\".format(si, len(li))\n"
    "            flat_parts.append(li)\n"
    "        return b\"\".join(flat_parts)\n"
    "\n"
    "\n"
    "class GarbageSerializer:\n"
    "    def __init__(self):\n"
    "        self.garbage_bufs = [[]]\n"
    "        self.parts = []\n"
    "        self.size = 0\n"
    "        self.garbage_pos = 0\n"
    "\n"
    "    def reset_garbage_pos(self):\n"
    "        self.garbage_bufs.append([])\n"
    "        self.garbage_pos = 0\n"
    "\n"
    "    def add(self, part):\n"
    "        assert isinstance(part, bytes)\n"
    "        self.parts.append(part)\n"
    "        self.garbage_bufs[-1].append((self.garbage_pos, part))\n"
    "        self.size += len(part)\n"
    "        self.garbage_pos += len(part)\n"
    "\n"
    "    def align(self, alignment):\n"
    "        new_size = (self.size + alignment - 1) & -alignment\n"
    "        self.add((new_size - self.size) * b\"\\0\")\n"
    "\n"
    "    def garbage_at(self, pos):\n"
    "        # Find the last write to position pos & 0xffff, assuming a cyclic\n"
    "        # buffer of size 0x10000 where the write position is reset to 0 on\n"
    "        # each call to reset_garbage_pos.\n"
    "        pos &= 0xFFFF\n"
    "        for bufs in self.garbage_bufs[::-1]:\n"
    "            for (bpos, buf) in bufs[::-1]:\n"
    "                q = ((bpos + len(buf) - 1 - pos) & ~0xFFFF) + pos\n"
    "                if q >= bpos:\n"
    "                    return buf[q - bpos]\n"
    "        return 0\n"
    "\n"
    "    def align_garbage(self, alignment):\n"
    "        while self.size % alignment != 0:\n"
    "            self.add(bytes([self.garbage_at(self.garbage_pos)]))\n"
    "\n"
    "    def finish(self):\n"
    "        return b\"\".join(self.parts)\n"
    "\n"
    "\n"
    "def validate_json_format(json, fmt, forstr=\"\"):\n"
    "    constructor_to_name = {\n"
    "        str: \"a string\",\n"
    "        dict: \"an object\",\n"
    "        int: \"an integer\",\n"
    "        float: \"a floating point number\",\n"
    "        list: \"an array\",\n"
    "    }\n"
    "    for key, tp in fmt.items():\n"
    "        validate(key in json, 'missing key \"' + key + '\"', forstr)\n"
    "        if isinstance(tp, list):\n"
    "            validate_int_in_range(json[key], tp[0], tp[1], '\"' + key + '\"', forstr)\n"
    "        else:\n"
    "            validate(\n"
    "                isinstance(json[key], tp)\n"
    "                or (tp == float and isinstance(json[key], int)),\n"
    "                '\"{}\" must be {}'.format(key, constructor_to_name[tp]),\n"
    "                forstr,\n"
    "            )\n"
    "\n"
    "\n"
    "def validate_int_in_range(val, lo, hi, msg, forstr=\"\"):\n"
    "    validate(isinstance(val, int), \"{} must be an integer\".format(msg), forstr)\n"
    "    validate(\n"
    "        lo <= val <= hi, \"{} must be in range {} to {}\".format(msg, lo, hi), forstr\n"
    "    )\n"
    "\n"
    "\n"
    "def validate_sound(json, sample_bank, forstr=\"\"):\n"
    "    validate_json_format(json, {\"sample\": str}, forstr)\n"
    "    if \"tuning\" in json:\n"
    "        validate_json_format(json, {\"tuning\": float}, forstr)\n"
    "    validate(\n"
    "        json[\"sample\"] in sample_bank.name_to_entry,\n"
    "        \"reference to sound {} which isn't found in sample bank {}\".format(\n"
    "            json[\"sample\"], sample_bank.name\n"
    "        ),\n"
    "        forstr,\n"
    "    )\n"
    "\n"
    "\n"
    "def validate_bank_toplevel(json):\n"
    "    validate(isinstance(json, dict), \"must have a top-level object\")\n"
    "    validate_json_format(\n"
    "        json,\n"
    "        {\n"
    "            \"envelopes\": dict,\n"
    "            \"sample_bank\": str,\n"
    "            \"instruments\": dict,\n"
    "            \"instrument_list\": list,\n"
    "        },\n"
    "    )\n"
    "\n"
    "\n"
    "def normalize_sound_json(json):\n"
    "    # Convert {\"sound\": \"str\"} into {\"sound\": {\"sample\": \"str\"}}\n"
    "    fixup = []\n"
    "    for inst in json[\"instruments\"].values():\n"
    "        if isinstance(inst, list):\n"
    "            for drum in inst:\n"
    "                fixup.append((drum, \"sound\"))\n"
    "        else:\n"
    "            fixup.append((inst, \"sound_lo\"))\n"
    "            fixup.append((inst, \"sound\"))\n"
    "            fixup.append((inst, \"sound_hi\"))\n"
    "    for (obj, key) in fixup:\n"
    "        if isinstance(obj, dict) and isinstance(obj.get(key, None), str):\n"
    "            obj[key] = {\"sample\": obj[key]}\n"
    "\n"
    "\n"
    "def validate_bank(json, sample_bank):\n"
    "    if \"date\" in json:\n"
    "        validate(\n"
    "            isinstance(json[\"date\"], str)\n"
    "            and re.match(r\"[0-9]{4}-[0-9]{2}-[0-9]{2}\\Z\", json[\"date\"]),\n"
    "            \"date must have format yyyy-mm-dd\",\n"
    "        )\n"
    "\n"
    "    for key, env in json[\"envelopes\"].items():\n"
    "        validate(isinstance(env, list), 'envelope \"' + key + '\" must be an array')\n"
    "        last_fine = False\n"
    "        for entry in env:\n"
    "            if entry in [\"stop\", \"hang\", \"restart\"]:\n"
    "                last_fine = True\n"
    "            else:\n"
    "                validate(\n"
    "                    isinstance(entry, list) and len(entry) == 2,\n"
    "                    'envelope entry in \"'\n"
    "                    + key\n"
    "                    + '\" must be a list of length 2, or one of stop/hang/restart',\n"
    "                )\n"
    "                if entry[0] == \"goto\":\n"
    "                    validate_int_in_range(\n"
    "                        entry[1], 0, len(env) - 2, \"envelope goto target out of range:\"\n"
    "                    )\n"
    "                    last_fine = True\n"
    "                else:\n"
    "                    validate_int_in_range(\n"
    "                        entry[0], 1, 2 ** 16 - 4, \"envelope entry's first part\"\n"
    "                    )\n"
    "                    validate_int_in_range(\n"
    "                        entry[1], 0, 2 ** 16 - 1, \"envelope entry's second part\"\n"
    "                    )\n"
    "                    last_fine = False\n"
    "        validate(\n"
    "            last_fine, 'envelope \"{}\" must end with stop/hang/restart/goto'.format(key)\n"
    "        )\n"
    "\n"
    "    drums = []\n"
    "    instruments = []\n"
    "    instrument_names = set()\n"
    "    for name, inst in json[\"instruments\"].items():\n"
    "        if name == \"percussion\":\n"
    "            validate(isinstance(inst, list), \"drums entry must be a list\")\n"
    "            drums = inst\n"
    "        else:\n"
    "            validate(isinstance(inst, dict), \"instrument entry must be an object\")\n"
    "            instruments.append((name, inst))\n"
    "            instrument_names.add(name)\n"
    "\n"
    "    for drum in drums:\n"
    "        validate(isinstance(drum, dict), \"drum entry must be an object\")\n"
    "        validate_json_format(\n"
    "            drum,\n"
    "            {\"release_rate\": [0, 255], \"pan\": [0, 128], \"envelope\": str, \"sound\": dict},\n"
    "        )\n"
    "        validate_sound(drum[\"sound\"], sample_bank)\n"
    "        validate(\n"
    "            drum[\"envelope\"] in json[\"envelopes\"],\n"
    "            \"reference to non-existent envelope \" + drum[\"envelope\"],\n"
    "            \"drum\",\n"
    "        )\n"
    "\n"
    "    no_sound = {}\n"
    "\n"
    "    for name, inst in instruments:\n"
    "        forstr = \"instrument \" + name\n"
    "        for lohi in [\"lo\", \"hi\"]:\n"
    "            nr = \"normal_range_\" + lohi\n"
    "            so = \"sound_\" + lohi\n"
    "            if nr in inst:\n"
    "                validate(so in inst, nr + \" is specified, but not \" + so, forstr)\n"
    "            if so in inst:\n"
    "                validate(nr in inst, so + \" is specified, but not \" + nr, forstr)\n"
    "            else:\n"
    "                inst[so] = no_sound\n"
    "        if \"normal_range_lo\" not in inst:\n"
    "            inst[\"normal_range_lo\"] = 0\n"
    "        if \"normal_range_hi\" not in inst:\n"
    "            inst[\"normal_range_hi\"] = 127\n"
    "\n"
    "        validate_json_format(\n"
    "            inst,\n"
    "            {\n"
    "                \"release_rate\": [0, 255],\n"
    "                \"envelope\": str,\n"
    "                \"normal_range_lo\": [0, 127],\n"
    "                \"normal_range_hi\": [0, 127],\n"
    "                \"sound_lo\": dict,\n"
    "                \"sound\": dict,\n"
    "                \"sound_hi\": dict,\n"
    "            },\n"
    "            forstr,\n"
    "        )\n"
    "\n"
    "        if \"ifdef\" in inst:\n"
    "            validate(\n"
    "                isinstance(inst[\"ifdef\"], list)\n"
    "                and all(isinstance(x, str) for x in inst[\"ifdef\"]),\n"
    "                '\"ifdef\" must be an array of strings',\n"
    "            )\n"
    "\n"
    "        validate(\n"
    "            inst[\"normal_range_lo\"] <= inst[\"normal_range_hi\"],\n"
    "            \"normal_range_lo > normal_range_hi\",\n"
    "            forstr,\n"
    "        )\n"
    "        validate(\n"
    "            inst[\"envelope\"] in json[\"envelopes\"],\n"
    "            \"reference to non-existent envelope \" + inst[\"envelope\"],\n"
    "            forstr,\n"
    "        )\n"
    "        for key in [\"sound_lo\", \"sound\", \"sound_hi\"]:\n"
    "            if inst[key] is no_sound:\n"
    "                del inst[key]\n"
    "            else:\n"
    "                validate_sound(inst[key], sample_bank, forstr)\n"
    "\n"
    "    seen_instruments = set()\n"
    "    for inst in json[\"instrument_list\"]:\n"
    "        if inst is None:\n"
    "            continue\n"
    "        validate(\n"
    "            isinstance(inst, str),\n"
    "            \"instrument list should contain only strings and nulls\",\n"
    "        )\n"
    "        validate(\n"
    "            inst in instrument_names, \"reference to non-existent instrument \" + inst\n"
    "        )\n"
    "        validate(\n"
    "            inst not in seen_instruments, inst + \" occurs twice in the instrument list\"\n"
    "        )\n"
    "        seen_instruments.add(inst)\n"
    "\n"
    "    for inst in instrument_names:\n"
    "        validate(inst in seen_instruments, \"unreferenced instrument \" + inst)\n"
    "\n"
    "\n"
    "def apply_version_diffs(json, defines):\n"
    "    if \"VERSION_EU\" in defines and isinstance(json.get(\"date\", None), str):\n"
    "        json[\"date\"] = json[\"date\"].replace(\"1996-03-19\", \"1996-06-24\")\n"
    "\n"
    "    ifdef_removed = set()\n"
    "    for key, inst in json[\"instruments\"].items():\n"
    "        if (\n"
    "            isinstance(inst, dict)\n"
    "            and isinstance(inst.get(\"ifdef\", None), list)\n"
    "            and all(d not in defines for d in inst[\"ifdef\"])\n"
    "        ):\n"
    "            ifdef_removed.add(key)\n"
    "    for key in ifdef_removed:\n"
    "        del json[\"instruments\"][key]\n"
    "        json[\"instrument_list\"].remove(key)\n"
    "\n"
    "\n"
    "def mark_sample_bank_uses(bank):\n"
    "    bank.sample_bank.uses.append(bank)\n"
    "\n"
    "    def mark_used(name):\n"
    "        bank.sample_bank.name_to_entry[name].used = True\n"
    "\n"
    "    for inst in bank.json[\"instruments\"].values():\n"
    "        if isinstance(inst, list):\n"
    "            for drum in inst:\n"
    "                mark_used(drum[\"sound\"][\"sample\"])\n"
    "        else:\n"
    "            if \"sound_lo\" in inst:\n"
    "                mark_used(inst[\"sound_lo\"][\"sample\"])\n"
    "            mark_used(inst[\"sound\"][\"sample\"])\n"
    "            if \"sound_hi\" in inst:\n"
    "                mark_used(inst[\"sound_hi\"][\"sample\"])\n"
    "\n"
    "\n"
    "def serialize_ctl(bank, base_ser):\n"
    "    json = bank.json\n"
    "\n"
    "    drums = []\n"
    "    instruments = []\n"
    "    for inst in json[\"instruments\"].values():\n"
    "        if isinstance(inst, list):\n"
    "            drums = inst\n"
    "        else:\n"
    "            instruments.append(inst)\n"
    "\n"
    "    y, m, d = map(int, json.get(\"date\", \"0000-00-00\").split(\"-\"))\n"
    "    date = y * 10000 + m * 100 + d\n"
    "    base_ser.add(\n"
    "        pack(\n"
    "            \"IIII\",\n"
    "            len(json[\"instrument_list\"]),\n"
    "            len(drums),\n"
    "            1 if len(bank.sample_bank.uses) > 1 else 0,\n"
    "            to_bcd(date),\n"
    "        )\n"
    "    )\n"
    "\n"
    "    ser = ReserveSerializer()\n"
    "    if drums:\n"
    "        drum_pos_buf = ser.reserve(WORD_BYTES)\n"
    "    else:\n"
    "        ser.add(b\"\\0\" * WORD_BYTES)\n"
    "        drum_pos_buf = None\n"
    "\n"
    "    inst_pos_buf = ser.reserve(WORD_BYTES * len(json[\"instrument_list\"]))\n"
    "    ser.align(16)\n"
    "\n"
    "    used_samples = []\n"
    "    for inst in json[\"instruments\"].values():\n"
    "        if isinstance(inst, list):\n"
    "            for drum in inst:\n"
    "                used_samples.append(drum[\"sound\"][\"sample\"])\n"
    "        else:\n"
    "            if \"sound_lo\" in inst:\n"
    "                used_samples.append(inst[\"sound_lo\"][\"sample\"])\n"
    "            used_samples.append(inst[\"sound\"][\"sample\"])\n"
    "            if \"sound_hi\" in inst:\n"
    "                used_samples.append(inst[\"sound_hi\"][\"sample\"])\n"
    "\n"
    "    sample_name_to_addr = {}\n"
    "    for name in used_samples:\n"
    "        if name in sample_name_to_addr:\n"
    "            continue\n"
    "        sample_name_to_addr[name] = ser.size\n"
    "        aifc = bank.sample_bank.name_to_entry[name]\n"
    "        sample_len = len(aifc.data)\n"
    "\n"
    "        # Sample\n"
    "        ser.add(pack(\"PP\", 0, aifc.offset))\n"
    "        loop_addr_buf = ser.reserve(WORD_BYTES)\n"
    "        book_addr_buf = ser.reserve(WORD_BYTES)\n"
    "        ser.add(pack(\"I\", align(sample_len, 2)))\n"
    "        ser.align(16)\n"
    "\n"
    "        # Book\n"
    "        book_addr_buf.append(pack(\"P\", ser.size))\n"
    "        ser.add(pack(\"ii\", aifc.book.order, aifc.book.npredictors))\n"
    "        for x in aifc.book.table:\n"
    "            ser.add(pack(\"h\", x))\n"
    "        ser.align(16)\n"
    "\n"
    "        # Loop\n"
    "        loop_addr_buf.append(pack(\"P\", ser.size))\n"
    "        if aifc.loop is None:\n"
    "            assert sample_len % 9 in [0, 1]\n"
    "            end = sample_len // 9 * 16 + (sample_len % 2) + (sample_len % 9)\n"
    "            ser.add(pack(\"IIiI\", 0, end, 0, 0))\n"
    "        else:\n"
    "            ser.add(pack(\"IIiI\", aifc.loop.start, aifc.loop.end, aifc.loop.count, 0))\n"
    "            assert aifc.loop.count != 0\n"
    "            for x in aifc.loop.state:\n"
    "                ser.add(pack(\"h\", x))\n"
    "        ser.align(16)\n"
    "\n"
    "    env_name_to_addr = {}\n"
    "    for name, env in json[\"envelopes\"].items():\n"
    "        env_name_to_addr[name] = ser.size\n"
    "        for entry in env:\n"
    "            if entry == \"stop\":\n"
    "                entry = [0, 0]\n"
    "            elif entry == \"hang\":\n"
    "                entry = [2 ** 16 - 1, 0]\n"
    "            elif entry == \"restart\":\n"
    "                entry = [2 ** 16 - 3, 0]\n"
    "            elif entry[0] == \"goto\":\n"
    "                entry[0] = 2 ** 16 - 2\n"
    "            # Envelopes are always written as big endian, to match sequence files\n"
    "            # which are byte blobs and can embed envelopes.\n"
    "            ser.add(struct.pack(\">HH\", *entry))\n"
    "        ser.align(16)\n"
    "\n"
    "    def ser_sound(sound):\n"
    "        sample_addr = (\n"
    "            0 if sound[\"sample\"] is None else sample_name_to_addr[sound[\"sample\"]]\n"
    "        )\n"
    "        if \"tuning\" in sound:\n"
    "            tuning = sound[\"tuning\"]\n"
    "        else:\n"
    "            aifc = bank.sample_bank.name_to_entry[sound[\"sample\"]]\n"
    "            tuning = aifc.sample_rate / 32000\n"
    "        ser.add(pack(\"PfX\", sample_addr, tuning))\n"
    "\n"
    "    no_sound = {\"sample\": None, \"tuning\": 0.0}\n"
    "\n"
    "    inst_name_to_pos = {}\n"
    "    for name, inst in json[\"instruments\"].items():\n"
    "        if isinstance(inst, list):\n"
    "            continue\n"
    "        inst_name_to_pos[name] = ser.size\n"
    "        env_addr = env_name_to_addr[inst[\"envelope\"]]\n"
    "        ser.add(\n"
    "            pack(\n"
    "                \"BBBBXP\",\n"
    "                0,\n"
    "                inst.get(\"normal_range_lo\", 0),\n"
    "                inst.get(\"normal_range_hi\", 127),\n"
    "                inst[\"release_rate\"],\n"
    "                env_addr,\n"
    "            )\n"
    "        )\n"
    "        ser_sound(inst.get(\"sound_lo\", no_sound))\n"
    "        ser_sound(inst[\"sound\"])\n"
    "        ser_sound(inst.get(\"sound_hi\", no_sound))\n"
    "    ser.align(16)\n"
    "\n"
    "    for name in json[\"instrument_list\"]:\n"
    "        if name is None:\n"
    "            inst_pos_buf.append(pack(\"P\", 0))\n"
    "            continue\n"
    "        inst_pos_buf.append(pack(\"P\", inst_name_to_pos[name]))\n"
    "\n"
    "    if drums:\n"
    "        drum_poses = []\n"
    "        for drum in drums:\n"
    "            drum_poses.append(ser.size)\n"
    "            ser.add(pack(\"BBBBX\", drum[\"release_rate\"], drum[\"pan\"], 0, 0))\n"
    "            ser_sound(drum[\"sound\"])\n"
    "            env_addr = env_name_to_addr[drum[\"envelope\"]]\n"
    "            ser.add(pack(\"P\", env_addr))\n"
    "        ser.align(16)\n"
    "\n"
    "        drum_pos_buf.append(pack(\"P\", ser.size))\n"
    "        for pos in drum_poses:\n"
    "            ser.add(pack(\"P\", pos))\n"
    "        ser.align(16)\n"
    "\n"
    "    base_ser.add(ser.finish())\n"
    "\n"
    "\n"
    "def serialize_tbl(sample_bank, ser):\n"
    "    ser.reset_garbage_pos()\n"
    "    base_addr = ser.size\n"
    "    for aifc in sample_bank.entries:\n"
    "        if not aifc.used:\n"
    "            continue\n"
    "        ser.align(16)\n"
    "        aifc.offset = ser.size - base_addr\n"
    "        ser.add(aifc.data)\n"
    "    ser.align(2)\n"
    "    ser.align_garbage(16)\n"
    "\n"
    "\n"
    "def serialize_seqfile(entries, serialize_entry, entry_list, magic, extra_padding=True):\n"
    "    ser = ReserveSerializer()\n"
    "    ser.add(pack(\"HHX\", magic, len(entry_list)))\n"
    "    table = ser.reserve(len(entry_list) * 2 * WORD_BYTES)\n"
    "    ser.align(16)\n"
    "    data_start = ser.size\n"
    "\n"
    "    ser2 = GarbageSerializer()\n"
    "    entry_offsets = []\n"
    "    entry_lens = []\n"
    "    for entry in entries:\n"
    "        entry_offsets.append(ser2.size)\n"
    "        serialize_entry(entry, ser2)\n"
    "        entry_lens.append(ser2.size - entry_offsets[-1])\n"
    "    ser.add(ser2.finish())\n"
    "    if extra_padding:\n"
    "        ser.add(b\"\\0\")\n"
    "    ser.align(64)\n"
    "\n"
    "    for ent in entry_list:\n"
    "        table.append(pack(\"P\", entry_offsets[ent] + data_start))\n"
    "        table.append(pack(\"IX\", entry_lens[ent]))\n"
    "    return ser.finish()\n"
    "\n"
    "\n"
    "def validate_and_normalize_sequence_json(json, bank_names, defines):\n"
    "    validate(isinstance(json, dict), \"must have a top-level object\")\n"
    "    if \"comment\" in json:\n"
    "        del json[\"comment\"]\n"
    "    for key, seq in json.items():\n"
    "        if isinstance(seq, dict):\n"
    "            validate_json_format(seq, {\"ifdef\": list, \"banks\": list}, key)\n"
    "            validate(\n"
    "                all(isinstance(x, str) for x in seq[\"ifdef\"]),\n"
    "                '\"ifdef\" must be an array of strings',\n"
    "                key,\n"
    "            )\n"
    "            if all(d not in defines for d in seq[\"ifdef\"]):\n"
    "                seq = None\n"
    "            else:\n"
    "                seq = seq[\"banks\"]\n"
    "            json[key] = seq\n"
    "        if isinstance(seq, list):\n"
    "            for x in seq:\n"
    "                validate(\n"
    "                    isinstance(x, str), \"bank list must be an array of strings\", key\n"
    "                )\n"
    "                validate(\n"
    "                    x in bank_names, \"reference to non-existing sound bank \" + x, key\n"
    "                )\n"
    "        else:\n"
    "            validate(seq is None, \"bad JSON type, expected null, array or object\", key)\n"
    "\n"
    "\n"
    "def write_sequences(\n"
    "    inputs, out_filename, out_bank_sets, sound_bank_dir, seq_json, defines\n"
    "):\n"
    "    bank_names = sorted(\n"
    "        [os.path.splitext(os.path.basename(x))[0] for x in os.listdir(sound_bank_dir)]\n"
    "    )\n"
    "\n"
    "    data = mext.seq_json();\n"
    "    data = strip_comments(data)\n"
    "    json = orderedJsonDecoder.decode(data)\n"
    "    validate_and_normalize_sequence_json(json, bank_names, defines)\n"
    "\n"
    "    inputs.sort(key=lambda f: os.path.basename(f))\n"
    "    name_to_fname = {}\n"
    "    for fname in inputs:\n"
    "        name = os.path.splitext(os.path.basename(fname))[0]\n"
    "        if name in name_to_fname:\n"
    "            fail(\n"
    "                \"Files \"\n"
    "                + fname\n"
    "                + \" and \"\n"
    "                + name_to_fname[name]\n"
    "                + \" conflict. Remove one of them.\"\n"
    "            )\n"
    "        name_to_fname[name] = fname\n"
    "        if name not in json:\n"
    "            fail(\n"
    "                \"Sequence file \" + fname + \" is not mentioned in sequences.json. \"\n"
    "                \"Either assign it a list of sound banks, or set it to null to \"\n"
    "                \"explicitly leave it out from the build.\"\n"
    "            )\n"
    "\n"
    "    for key, seq in json.items():\n"
    "        if key not in name_to_fname and seq is not None:\n"
    "            fail(\n"
    "                \"sequences.json assigns sound banks to \"\n"
    "                + key\n"
    "                + \", but there is no such sequence file. Either remove the entry (or \"\n"
    "                \"set it to null), or create sound/sequences/\" + key + \".m64.\"\n"
    "            )\n"
    "\n"
    "    ind_to_name = []\n"
    "    for key in json:\n"
    "        ind = int(key.split(\"_\")[0], 16)\n"
    "        while len(ind_to_name) <= ind:\n"
    "            ind_to_name.append(None)\n"
    "        if ind_to_name[ind] is not None:\n"
    "            fail(\n"
    "                \"Sequence files \"\n"
    "                + key\n"
    "                + \" and \"\n"
    "                + ind_to_name[ind]\n"
    "                + \" have the same index. Renumber or delete one of them.\"\n"
    "            )\n"
    "        ind_to_name[ind] = key\n"
    "\n"
    "    while ind_to_name and json.get(ind_to_name[-1], None) is None:\n"
    "        ind_to_name.pop()\n"
    "\n"
    "    def serialize_file(name, ser):\n"
    "        if json.get(name, None) is None:\n"
    "            return\n"
    "        ser.reset_garbage_pos()\n"
    "        with open(name_to_fname[name], \"rb\") as f:\n"
    "            ser.add(f.read())\n"
    "        ser.align_garbage(16)\n"
    "\n"
    "    with open(out_filename, \"wb\") as f:\n"
    "        n = range(len(ind_to_name))\n"
    "        f.write(serialize_seqfile(ind_to_name, serialize_file, n, 3, False))\n"
    "\n"
    "    with open(out_bank_sets, \"wb\") as f:\n"
    "        ser = ReserveSerializer()\n"
    "        table = ser.reserve(len(ind_to_name) * 2)\n"
    "        for name in ind_to_name:\n"
    "            bank_set = json.get(name, None)\n"
    "            if bank_set is None:\n"
    "                bank_set = []\n"
    "            table.append(pack(\"H\", ser.size))\n"
    "            ser.add(bytes([len(bank_set)]))\n"
    "            for bank in bank_set[::-1]:\n"
    "                ser.add(bytes([bank_names.index(bank)]))\n"
    "        ser.align(16)\n"
    "        f.write(ser.finish())\n"
    "\n"
    "\n"
    "def main():\n"
    "    global STACK_TRACES\n"
    "    global ENDIAN_MARKER\n"
    "    global WORD_BYTES\n"
    "    need_help = False\n"
    "    skip_next = 0\n"
    "    cpp_command = None\n"
    "    print_samples = False\n"
    "    sequences_out_file = None\n"
    "    defines = []\n"
    "    args = []\n"
    "    for i, a in enumerate(sys.argv[1:], 1):\n"
    "        if skip_next > 0:\n"
    "            skip_next -= 1\n"
    "            continue\n"
    "        if a == \"--help\" or a == \"-h\":\n"
    "            need_help = True\n"
    "        elif a == \"--cpp\":\n"
    "            cpp_command = sys.argv[i + 1]\n"
    "            skip_next = 1\n"
    "        elif a == \"-D\":\n"
    "            defines.append(sys.argv[i + 1])\n"
    "            skip_next = 1\n"
    "        elif a == \"--endian\":\n"
    "            endian = sys.argv[i + 1]\n"
    "            if endian == \"big\":\n"
    "                ENDIAN_MARKER = \">\"\n"
    "            elif endian == \"little\":\n"
    "                ENDIAN_MARKER = \"<\"\n"
    "            elif endian == \"native\":\n"
    "                ENDIAN_MARKER = \"=\"\n"
    "            else:\n"
    "                fail(\"--endian takes argument big, little or native\")\n"
    "            skip_next = 1\n"
    "        elif a == \"--bitwidth\":\n"
    "            bitwidth = sys.argv[i + 1]\n"
    "            if bitwidth == 'native':\n"
    "                WORD_BYTES = struct.calcsize('P')\n"
    "            else:\n"
    "                if bitwidth not in ['32', '64']:\n"
    "                    fail(\"--bitwidth takes argument 32, 64 or native\")\n"
    "                WORD_BYTES = int(bitwidth) // 8\n"
    "            skip_next = 1\n"
    "        elif a.startswith(\"-D\"):\n"
    "            defines.append(a[2:])\n"
    "        elif a == \"--stack-trace\":\n"
    "            STACK_TRACES = True\n"
    "        elif a == \"--print-samples\":\n"
    "            print_samples = True\n"
    "        elif a == \"--sequences\":\n"
    "            sequences_out_file = sys.argv[i + 1]\n"
    "            bank_sets_out_file = sys.argv[i + 2]\n"
    "            sound_bank_dir = sys.argv[i + 3]\n"
    "            sequence_json = sys.argv[i + 4]\n"
    "            skip_next = 4\n"
    "        elif a.startswith(\"-\"):\n"
    "            print(\"Unrecognized option \" + a)\n"
    "            # sys.exit(1)\n"
    "        else:\n"
    "            args.append(a)\n"
    "\n"
    "    defines_set = {d.split(\"=\")[0] for d in defines}\n"
    "\n"
    "    if sequences_out_file is not None and not need_help:\n"
    "        write_sequences(\n"
    "            args,\n"
    "            sequences_out_file,\n"
    "            bank_sets_out_file,\n"
    "            sound_bank_dir,\n"
    "            sequence_json,\n"
    "            defines_set,\n"
    "        )\n"
    "        mext.print('Writing done!')\n"
    "        return\n"
    "        # sys.exit\n"
    "\n"
    "    if need_help or len(args) != 4:\n"
    "        print(\n"
    "            \"Usage: {} <samples dir> <sound bank dir>\"\n"
    "            \" <out .ctl file> <out .tbl file>\"\n"
    "            \" [--cpp <preprocessor>]\"\n"
    "            \" [-D <symbol>]\"\n"
    "            \" [--stack-trace]\"\n"
    "            \" | --sequences <out sequence .bin> <out bank sets .bin> <sound bank dir> \"\n"
    "            \"<sequences.json> <inputs...>\".format(sys.argv[0])\n"
    "        )\n"
    "        # sys.exit(0 if need_help else 1)\n"
    "\n"
    "    sample_bank_dir = args[0]\n"
    "    sound_bank_dir = args[1]\n"
    "    ctl_data_out = args[2]\n"
    "    tbl_data_out = args[3]\n"
    "\n"
    "    banks = []\n"
    "    sample_banks = []\n"
    "    name_to_sample_bank = {}\n"
    "\n"
    "    sample_bank_names = sorted(os.listdir(sample_bank_dir))\n"
    "    for name in sample_bank_names:\n"
    "        dir = os.path.join(sample_bank_dir, name)\n"
    "        if not os.path.isdir(dir):\n"
    "            continue\n"
    "        entries = []\n"
    "        for f in sorted(os.listdir(dir)):\n"
    "            fname = os.path.join(dir, f)\n"
    "            if not f.endswith(\".aifc\"):\n"
    "                continue\n"
    "            try:\n"
    "                with open(fname, \"rb\") as inf:\n"
    "                    data = inf.read()\n"
    "                    entries.append(parse_aifc(data, f[:-5], fname))\n"
    "            except Exception as e:\n"
    "                fail(\"malformed AIFC file \" + fname + \": \" + str(e))\n"
    "        if entries:\n"
    "            sample_bank = SampleBank(name, entries)\n"
    "            sample_banks.append(sample_bank)\n"
    "            name_to_sample_bank[name] = sample_bank\n"
    "\n"
    "    bank_names = sorted(os.listdir(sound_bank_dir))\n"
    "    for f in bank_names:\n"
    "        fname = os.path.join(sound_bank_dir, f)\n"
    "        if not f.endswith(\".json\"):\n"
    "            continue\n"
    "\n"
    "        try:\n"
    "            if cpp_command:\n"
    "                data = subprocess.run(\n"
    "                    [cpp_command, fname] + [\"-D\" + x for x in defines],\n"
    "                    stdout=subprocess.PIPE,\n"
    "                    check=True,\n"
    "                ).stdout.decode()\n"
    "            else:\n"
    "                with open(fname, \"r\") as inf:\n"
    "                    data = inf.read()\n"
    "                data = strip_comments(data)\n"
    "            bank_json = orderedJsonDecoder.decode(data)\n"
    "\n"
    "            validate_bank_toplevel(bank_json)\n"
    "            apply_version_diffs(bank_json, defines_set)\n"
    "            normalize_sound_json(bank_json)\n"
    "\n"
    "            sample_bank_name = bank_json[\"sample_bank\"]\n"
    "            validate(\n"
    "                sample_bank_name in name_to_sample_bank,\n"
    "                \"sample bank \" + sample_bank_name + \" not found\",\n"
    "            )\n"
    "            sample_bank = name_to_sample_bank[sample_bank_name]\n"
    "\n"
    "            validate_bank(bank_json, sample_bank)\n"
    "\n"
    "            bank = Bank(f[:-5], sample_bank, bank_json)\n"
    "            mark_sample_bank_uses(bank)\n"
    "            banks.append(bank)\n"
    "\n"
    "        except Exception as e:\n"
    "            fail(\"failed to parse bank \" + fname + \": \" + str(e))\n"
    "\n"
    "    sample_banks = [b for b in sample_banks if b.uses]\n"
    "    sample_banks.sort(key=lambda b: b.uses[0].name)\n"
    "    sample_bank_index = {}\n"
    "    for sample_bank in sample_banks:\n"
    "        sample_bank_index[sample_bank] = len(sample_bank_index)\n"
    "\n"
    "    with open(tbl_data_out, \"wb\") as out:\n"
    "        out.write(\n"
    "            serialize_seqfile(\n"
    "                sample_banks,\n"
    "                serialize_tbl,\n"
    "                [sample_bank_index[x.sample_bank] for x in banks],\n"
    "                TYPE_TBL,\n"
    "            )\n"
    "        )\n"
    "\n"
    "    with open(ctl_data_out, \"wb\") as out:\n"
    "        if DUMP_INDIVIDUAL_BINS:\n"
    "            # Debug logic, may simplify diffing\n"
    "            os.makedirs(\"ctl/\", exist_ok=True)\n"
    "            for b in banks:\n"
    "                with open(\"ctl/\" + b.name + \".bin\", \"wb\") as f:\n"
    "                    ser = GarbageSerializer()\n"
    "                    serialize_ctl(b, ser)\n"
    "                    f.write(ser.finish())\n"
    "            print(\"wrote to ctl/\")\n"
    "\n"
    "        out.write(\n"
    "            serialize_seqfile(banks, serialize_ctl, list(range(len(banks))), TYPE_CTL)\n"
    "        )\n"
    "\n"
    "    if print_samples:\n"
    "        for sample_bank in sample_banks:\n"
    "            for entry in sample_bank.entries:\n"
    "                if entry.used:\n"
    "                    print(entry.fname)\n"
    "\n"
    "\n"
    "if __name__ == \"__main__\":\n"
    "    main()\n"
    "\0"
};

#endif